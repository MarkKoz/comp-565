% !TEX output_directory = ./.temp/report
% !TEX options = --shell-escape

\documentclass[a4paper, 12pt]{scrartcl}
\usepackage[assign-num=3]{report}
\usepackage[outputdir=./.temp/report]{minted}

\title{Comparison of Game Engines}

\begin{document}

\maketitle

\section{Introduction}
A game engine is a tool for developers of video games. It is software framework which abstracts away core parts of a video game such as rendering, physics, input handling, sound, AI, etc. It typically includes software libraries and other software in the form of a software development kit (SDK), which contains additional tools revolving around the engine's ecosystem (level editor, asset packager, and so on).

A game engine enables developers to create games more efficiently, since a lot of the fundamental components of a game are available for use out of the box. This saves developers the time of having to implement all these core features from scratch, which could otherwise add a tremendous amount of complexity to the project. For example, game engines may offer cross-platform capabilities in a more or less transparent way to the developers. This removes the necessity to deal with the plethora of different platform-specific APIs, which allows developers and publishers to reach a broader market more easily.

\subsection{History}
Game engines were not immediately prevalent in the industry when it first started. This is because the platforms were much more fragmented, and there was little standardisation (and thus little compatibility) among them. Furthermore, hardware was being developed at a rapid pace. All these factors made it difficult to re-use any abstractions (such as those provided by a game engine) in the long term. Hardware was also quite limited, so it was necessary to build a game's components from scratch and custom-tailor them to the target platform to ensure the game ran optimally.

The earliest software that may constitute a game engine was in-house for use with first-party software. These engines were far more limited in scope than modern game engines (what may now be considered \textit{middleware} used by a game engine). Engines for third-parties became prevalent in the 1990s along with the growing popularity and feasibility of 3D graphics. This led to influential engines such as id Tech and Unreal Engine, which are in some form or another still in use with modern games.

Such engines were developed for first-party games, but made available for licensing to third-party developers. Companies shifted their strategy to developing the game and its engine separately. This decoupling enabled the engine to be usable by third parties, and allowed developers to become more specialised.

\section{Comparing Source and Unity}
This section compares and contrasts various aspects of two different engines: Source by Valve Software and Unity by Unity Technologies.

\subsection{Development Environment}
\subsubsection{Source}
Programming is done in C++, typically using Visual Studio. However, other IDEs can also work. A level editor named \textit{Hammer} is included in the Source SDK. When not programming or making assets, this is tool that is being worked with the most. It is used to define the level's geometry, apply textures, light the level, place objects and entities, configure behaviour logic for entities, and much more.

\begin{figure}[!htp]
  \centering
  \includegraphics[width=\linewidth]{images/source_hammer.png}
  \caption{Hammer editing \textit{cs\_office} from CS:GO}
\end{figure}

Assets such as models and textures are expected to be created using third-party tools. For modelling, Autodesk XSI and Maya were historically popular. However, it's more common these days to use one of the third-party plugins for other modelling tools such as Blender.

Some assets, including models and textures, are expected to be in Source-specific formats. To achieve this, the Source SDK provides some command-line tools to convert assets to the expected formats. For example, \texttt{vtex} is used for texture conversion and \texttt{studiomdl} is used to compile models. There are various other command-line tools, like \texttt{vbsp}, \texttt{vvis}, and \texttt{vrad} for map compilation and \texttt{vpk} for packaging game assets.

There are also third-party tools frequently used by modders and level designers, such as VIDE, which can be used to create textures, view or create game content packages, edit particles, pack game content into map files, and much more.

\begin{figure}[!htp]
  \centering
  \includegraphics[width=\linewidth]{images/source_vide_pakfile.png}
  \caption{VIDE displaying the pakfile lump of a map}
\end{figure}

\subsubsection{Unity}
The primary development environment for Unity is the Unity Editor. This environment is quite integrated; the Source engine's environment looks dated and fragmented in comparison. Like Hammer, Unity Editor can define the geometry of a scene and apply textures to objects. But it could also do a lot more, like creating animations and materials, running the game within, inspecting a running game's state, designing UIs, creating visual effects, and profiling the game.

\begin{figure}[!htp]
  \centering
  \includegraphics[width=\linewidth]{images/unity_editor.png}
  \caption{Unity Editor}
\end{figure}

The Unity environment is much more extensible than Source. Its package management system makes it easy to obtain first and third-party extensions to the Unity Editor. This same mechanism can also be used to import third-party assets from the internet. In general, using assets is easier compared to Source since Unity supports standard formats, and can even automatically convert formats in some cases.

For scripting, Unity Editor allows scripts to be edited with virtually any text editor. It also natively supports deeper integration with several IDEs: Visual Studio, Visual Studio Code, and JetBrains Rider.

\subsection{Programming}
\subsubsection{Source}
The engine itself is written in C++ so naturally, programming a game with the Source engine is also done in C++. The full source code of the engine can be licensed. Valve also offers a portion of the engine's C++ code with the Source SDK. This is enough to make a game with the SDK, but it doesn't give access to the engine's internals such as its core networking code. The Source engine also comes with it's own Standard Template Library named \texttt{CUtl}, which is located within the \texttt{Tier1} library of the engine.

\paragraph{Scripts}
The engine also supports external scripts using the VScript virtual machine and API. Depending on the version of the SDK, different languages are supported. VScript first shipped with support for the Squirrel language. However, Source Filmmaker uses Python and Portal 2 has limited Lua support.

\begin{figure}[!htp]
  \begin{minted}[
    linenos,
    autogobble=true,
    fontsize=\fontsize{10}{10},
  ]{js}
    function GiveGun(weapon, playerarray) {
      local equipper = Entities.CreateByClassname("game_player_equip")
      equipper.__KeyValueFromInt("spawnflags", 5)
      equipper.__KeyValueFromInt(weapon, 0)
      equipper.ValidateScriptScope()

      for (player in playerarray) {
        EntFireByHandle(equipper, "Use", "", 0, player, null)
      }

      EntFireByHandle(equipper, "Kill", "", 0.1, null, null)
    }
  \end{minted}
  \caption{VScript in Squirrel for CS:GO which equips players}
  \label{fig:source_vscript}
\end{figure}

Scripts can be attached to any entity via the \textit{Entity Scripts} property. Multiple scripts can be attached to an entity simultaneously. The input \texttt{RunScriptCode} can be used to execute VScript code within the script scope of the target entity's attached scripts. Similarly, \texttt{CallScriptFunction} can be used to call a function. There is also \texttt{RunScriptFile}, which can be used to run a script from disk and merge its contents with the script scope of the target entity. Inputs and outputs for entities will be discussed in more detail shortly.

It is technically possible to add support for scripting with any language, without relying on VScript. Garry's mod did this with Lua, and there is also a project by modders which added Python support.

\paragraph{I/O Entities}
Besides directly programming in C++ and VScript, there is an I/O system by which entities communicate between each other. This system can be leveraged to program entities in Hammer. Effectively, an entity's event can be hooked so that an action is performed on another entity when the event occurs.

For example, \cref{fig:source_entities} shows some of the entities used to control an elevator. The four stacked \texttt{logic\_relay}s control the doors for each of the four floors. The \texttt{logic\_compare} chooses the next path node for the elevator to travel to. The \texttt{logic\_relay} at the bottom right performs actions when the elevator needs to stop.

\begin{figure}[!htp]
  \centering
  \includegraphics[width=0.75\linewidth]{images/source_io_entities.png}
  \caption{Logic entities for controlling an elevator}
  \label{fig:source_entities}
\end{figure}

The last \texttt{logic\_relay} is pictured in more detail in \cref{fig:source_elev_stop}. The purpose of a \texttt{logic\_relay} is to forward messages; it can turn one input into many outputs. Another entity can trigger the relay, which causes the relay to fire an \texttt{OnTrigger} event. \texttt{elev\_stop} is being triggered by the aforementioned \texttt{logic\_compare}. \texttt{elev\_stop} has four outputs that occur when the \texttt{OnTrigger} event is fired. Each output targets a different entity and sends it some input. The first stops the elevator, the second plays a bell sound, and the last two open doors.

\begin{figure}[!htp]
  \centering
  \subfloat[\centering inputs]{
    \includegraphics[width=0.45\linewidth]{images/source_io_elev_stop_in.png}
  }
  \qquad
  \subfloat[\centering outputs]{
    \includegraphics[width=0.45\linewidth]{images/source_io_elev_stop_out.png}
  }
  \caption{The configured I/O of the \texttt{logic\_relay} entity named \texttt{elev\_stop}}
  \label{fig:source_elev_stop}
\end{figure}

\paragraph{Events}
There are many other events, such as one for the player getting hurt or a team winning a round. Data can be associated with an event, for example, which player got hurt or which team won. The \texttt{logic\_eventlistener} entity can be used to listen to events. In C++, \texttt{CGameEventListener::ListenForGameEvent} can be used. The \texttt{CGameEventManager} class can be used to interact with events, be it creating a new event, firing an event, or registering an event listener. Events are declared in various \texttt{.res} files in the \textit{resources} directory of the game. These get loaded using \texttt{CGameEventManager::LoadEventsFromFile}.

\begin{figure}[!htp]
  \begin{minted}[
    linenos,
    autogobble=true,
    fontsize=\fontsize{10}{10},
  ]{js}
    "game_end"              // a game ended
    {
      "winner"  "byte"      // winner team/user id
    }

    "round_start"
    {
      "timelimit" "long"    // round time limit in seconds
      "fraglimit" "long"    // frag limit in seconds
      "objective" "string"  // round objective
    }
  \end{minted}
  \caption{A portion of CS:GO's \textit{resource/gameevents.res}}
  \label{fig:source_gameevents}
\end{figure}

\subsubsection{Unity}
The Unity engine is written in C++. For a fee, it is possible to license the engine's source code and modify it directly. Unlike the Source engine, there is no free offering of a portion of the engine's source code. Thus, for most, the only option is to use Unity's C\# scripting APIs. Thankfully, these APIs are far more powerful and comprehensive than the Source engine's.

\paragraph{Scripts}
Scripts can be attached to game objects as components. This is similar to VScripts in the sense that VScripts can be attached to any entity. The inspector in Unity Editor will show all public fields of the script in the component's UI. There isn't an equivalent to this for VScripts. It's possible to access other scripts' public fields programmatically by getting the script components of other game objects.

\begin{figure}[!htp]
  \centering
  \includegraphics[scale=0.75]{images/unity_script_inspector.png}
  \caption{Setting a script's public fields in the inspector}
  \label{fig:unity_script_inspector}
\end{figure}

Scripts have an \texttt{Update} function which is called every frame. This is similar to the ``think'' function that VScripts have. They also have a \texttt{Start} function which is called before frames start being updated, so it's useful for initialisation code. Neither function has to be used though. For example, it may be desirable to have a script that holds functions used to handle events. Such functions can be hooked up using the inspector.

\begin{figure}[!htp]
  \begin{minted}[
    linenos,
    autogobble=true,
    fontsize=\fontsize{10}{10},
  ]{cs}
    using UnityEngine;

    public class ColourChanger : MonoBehaviour {
        private void Start() {
            Debug.Log("Starting ColourChanger.");
        }

        private void Update() {
            GetComponent<Renderer>().material.color = Random.ColorHSV();
        }
    }
  \end{minted}
  \caption{Script which sets a random colour for the object every frame}
  \label{fig:unity_script}
\end{figure}

\paragraph{Events}
Some events have already been discussed, such as \texttt{Start} and \texttt{Update}. There are many other built-in events, such as UI events (e.g. clicking a button) and physics events (e.g. collision detection).

Custom events can be created using \texttt{UnityEvent} objects. If one is added as a public field of a script, it's possible to add a callback along with an argument for the event via the inspector. This is similar to the outputs menu in Hammer, but with a nicer interface; the editor displays a different UI component depending on the data type of the argument. For example, in \cref{fig:unity_event_inspector}, the argument is represented by a check box since it is a \texttt{bool}.

Alternatively, event listeners can be attached programmatically with \texttt{UnityEvent\-.AddListener}. Events can be invoked programmatically with \texttt{UnityEvent.Invoke}.

\begin{figure}[!htp]
  \centering
  \includegraphics[scale=0.75]{images/unity_event_inspector.png}
  \caption{Attaching a function to a button's \texttt{onClick} event}
  \label{fig:unity_event_inspector}
\end{figure}

There is also a general-purpose messaging system, which can be used to send custom messages to any game object which is registered to receive them. To create a custom message, an interface implementing \texttt{IEventSystemHandler} can be defined with some event handling functions. Then, any game object's script can implement this interface and define concrete event handlers. \texttt{ExecuteEvents.Execute} can be called with a specific \texttt{IEventSystemHandler}, a target game object, and a function in the interface. Any component of the target which implements the interface will have the specified function executed.

\subsection{Input}
\subsubsection{Source}
\subsubsection{Unity}

\subsection{Assets}
\subsubsection{Source}
\subsubsection{Unity}

\subsection{Physics}
\subsubsection{Source}
\subsubsection{Unity}

\subsection{Graphics}
\subsubsection{Source}
\subsubsection{Unity}

\subsection{AI}
\subsubsection{Source}
The Source engine has a sophisticated AI system. This system is separate from its choreography system, which won't be part of the discussion. Like all entities, NPCs have a \texttt{Think} function which allows the NPC to schedule code to run in the future. Thinks can be continuously rescheduled to effectively make an entity autonomous. Every time an NPC thinks to make a decision, it follows these steps:

\begin{enumerate}
  \item Perform sensing
  \item Generate a list of conditions
  \item Choose an appropriate state
  \item Selected a new schedule if appropriate
  \item Perform the current task
\end{enumerate}

\paragraph{Sensing}
Sensing is the process of generating a list of entities that an NPC can see and a list of sounds it can hear. These can be filtered out to ignore sights and sounds the NPC shouldn't care about.

An NPC has a potentially visible set (PVS), which is the spatial area that may be visible to the NPC at its current location. When an entity enters the PVS, there a viewcone test is performed to more accurately determine if the NPC can see this entity. The viewcone represents the spatial geometry of the NPC's current visual field, which is determined by the NPC's range (the viewcone's ``depth'') and its field of view (the viewcone's ``scope''). If an entity is within the viewcone, then a line-of-sight test is performed by casting a ray from the NPC to the entity. This determines if the view of the entity is obstructed by another object.

Similar to the PVS, there is a potentially audible set, which is the spatial area that may be audible to the NPC. However, unlike the PVS, there are no further steps involving the viewcone or LOS.

\paragraph{Conditions}
Conditions are flags stored on the NPC which represent some state in the world. They are determined from the sensed sights and sounds. For example, a condition may be set for when an enemy is seen, or when the NPC goes underwater. Conditions can also be used to interrupt schedules. For example, if a condition is set for choosing a new enemy, then this will interrupt a running schedule for chasing the current enemy.

\paragraph{State}
An NPC's state is based upon its conditions. In a sense, a state itself can be thought of as a condition, but in a much broader sense. However, an NPC can only be in one state. Examples of states include being dead, being in combat, and being idle.

\paragraph{Schedule}
The state, together with the conditions, are used to determine an appropriate schedule for the NPC. A schedule is a list of tasks for the NPC to perform, so it can be thought of as an overall action which the NPC is carrying out. An example of a schedule is an NPC taking cover to reload their weapon. An NPC can only have one schedule, and a new schedule is only chosen when there is no active one (due to the previous schedule being completed, failed, or interrupted).

\paragraph{Tasks}
A task is a discrete action within a schedule. Tasks are performed serially until the schedule is completed. Following the example schedule of taking cover to reload, the following tasks would be performed:

\begin{enumerate}
  \item Find a location for cover
  \item Find a path to that location
  \item Traverse the path
  \item Reload the gun
\end{enumerate}

\paragraph{Behaviours}
Behaviours are an abstraction of AI code. They can be re-used by many NPCs rather than being coupled to a single type of NPC. Some pre-existing behaviours include following another NPC, leading the player to a location, or appearing to be ``busy'' (performing some inconsequential action or idling).

\paragraph{Navigation}
NPCs can navigate via a node graph or via a navigation mesh. Typically, the latter is used by ``bots'', though there is a more general-purpose \textit{NextBot} system in some of Valve's games which makes use of navigation meshes. However, it is not available in any public Source SDK release. A navigation mesh can be auto-generated and also manually edited in-game. In contrast, a node graph is generated from manually placed node entities within a map.

\begin{figure}[!htp]
  \centering
  \includegraphics[width=\linewidth]{images/source_node_graph.jpg}
  \caption{A node graph in the penultimate map of Half-Life 2: Episode One}
  \label{fig:source_node_graph}
\end{figure}

\begin{figure}[!htp]
  \centering
  \includegraphics[width=\linewidth]{images/source_nav_mesh.png}
  \caption{Editing a navigation mesh in-game}
  \label{fig:source_nav_mesh}
\end{figure}

\paragraph{Other Features}
There are many other features in the AI system. There is an entire response system to manage speech and dialogue. NPCs can be in squads, which allows them to cover each other, move as a unit, share information, etc. Squads or single NPCs can also be programmed to perform an assault, in which they rally to points and, on cue, commence an assault on one or more points in the world. An NPC can have a relationship with another NPC, such as liking, fearing, or hating another NPCs. For example, if an NPC is fearful of another, they may flee or take cover from them.

\subsubsection{Unity}

\subsection{Networking}
\subsubsection{Source}
\subsubsection{Unity}

\subsection{Platforms}
\subsubsection{Source}
\subsubsection{Unity}

\end{document}
